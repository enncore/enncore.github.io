
<!DOCTYPE html> <html lang="en">

<head> <meta charset="utf-8"> <meta name="viewport"
content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta
name="description" content="Security for all in an AI-enabled society">
<meta name="author" content="EnnCore Team"> <title>Security for all in
an AI-enabled society</title>

    <!-- Bootstrap core CSS --> <link
    href="bootstrap/css/bootstrap.min.css" rel="stylesheet"> <link
    href="css/style.css" rel="stylesheet"> <link
    href="https://fonts.googleapis.com/css?family=Titillium+Web"
    rel="stylesheet">

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script
    src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.
    js"></script> <script
    src="bootstrap/js/bootstrap.bundle.min.js"></script> <script
    src="bootstrap/js/popper.min.js"></script>

    <style> .custom-popover { max-width: 400px; } .custom-popover
    .popover-header { background-color:rgb(222, 240, 255); } </style>
    </head>

<body id="secaiws"> <header id="header"
class="container-fluid"></header>

    <!-- Page Content --> <div class="container"> <div class="row mb-2">
    <div class="col-lg-12 text-center"> <h1 class="mt-5"> Workshop on General-Purpose AI: Prospects and Risks</h1> 
    </div> </div>
    <br>
    <br>
        <div class="row mt-2 mb-2"> <section class="col-lg-12"> <p> 
        This is a second workshop organised by the project EnnCore's team, with 
        the first workshop being held at Manchester in July 2023 
        (<a href="https://enncore.github.io/events/secaiws/">https://enncore.github.io/events/secaiws/</a>). 
        
        <a
        href="https://enncore.github.io/" target="_blank">EnnCore:
        End-to-End Conceptual Guarding of Neural Architectures</a> is a research project funded by the EPSRC under 
        the call <a
        href="https://gow.epsrc.ukri.org/NGBOViewPanelROL.aspx?PanelId=1
        -7RZQS3&RankingListId=1-7RZQW6" target="_blank">"Security for
        all in an AI enabled society"</a>, together with several other projects: <a
        href="https://research-information.bris.ac.uk/en/projects/chai-
        cyber-hygiene-in-ai-enabled-domestic-life" target="_blank">CHAI:
        Cyber Hygiene in AI enabled domestic life</a>, <a
        href="https://secure-ai-assistants.github.io/"
        target="_blank">SAIS: Secure AI assistantS</a>, and <a
        href="https://www.macs.hw.ac.uk/aisec/" target="_blank">AISEC:
        AI Secure and Explainable by Construction</a>.
        These projects focus on challenges at the intersection between
        Artificial Intelligence (AI) and Cyber-Security, including
        security for AI and AI for security, aiming for better and more
        widespread adoption of trusted and secure AI systems.  </p> 
        
        
        <p>In this workshop, we will be specifically 
        interested in the <b>General-purpose AI (GPAI) models</b>, sometimes called foundation models. 
        GPAI models have a wide range of applications, from chatbot, to code generation, to scientific discovery. 
        However, their vulnerabilities were also discovered and widely concerned. 
        The project EnnCore, sponsored by the EPSRC to work on the verification and explanation of neural 
        architectures, is coming to the end. In its lifespan of 5 years, the EnnCore team has been closely 
        monitoring the progress of the AI, from the days where convolutional neural networks are dominantly 
        studied, to today where a significant proportion of research has been shifted to study the GPAI. One 
        question remains across these models, that is, <b>can the risks of machine learning models be sufficiently 
        quantified?</b> A mathematically proved quantification of risks can provide not only the trust to the AI models 
        but also the evidence to the regulators about their good characteristics. This workshop invites experts in the 
        field to share their research progresses, thoughts, as well as the insights to this grand challenge of GPAI.   </p>
        </p>
        
        <p>Participants will leave having a better idea what the risks are, how to safeguard AI models against the risks, and 
        how to certify the certain to which an AI model is free from the risks.  
        Therefore, we will foster the dialogue
        between contemporary neural models and full-stack
        neural software verification.</p>
         
        <p> The workshop will be held at Liverpool, where the University of Liverpool is the second site of the EnnCORE project. 
        The workshop will have invited talks, poster presentations, and a roundtable discussion regarding Safety of GPAI.
        </p>
        
         <p>The event will occur in the <b>afternoon of Monday 
        June 9th, 2025</b> in <a href="https://maps.app.goo.gl/K7yRRJXvL3Q4ChZG9">Rendall Building</a> (Seminar Room 4), Liverpool L69 3BX.  </p>
        
        
        <p>Participants can find information about
        parking their cars at <a href="https://www.liverpool.ac.uk/maps/visiting/car-parking/#:~:text=Visitor%20car%20parking&text=Our%20two%20on%2Dcampus%20visitor,for%20visitor%20car%20park%20locations.">visitor car parking</a>. </p> 
        
         </section> </div>

        <div class="row mt-2 mb-2"> <section class="col-lg-12">
        <h1>Program</h1> <table> <thead> <tr> <th>Timing</th>
        <th>Talk</th> </tr> </thead> <tbody> <tr> <td>12:30 - 13:00</td>
        <td>Arrival, sandwiches, and coffee </td> </tr>
        <tr> <td>13:00 - 13:10</td> <td> Welcome and introduction </td> </tr> 
        
        <tr> <td>13:10 - 13.30</td> <td> Inverting Large Language Models, by Adrians Skapars, Edoardo Manino and Lucas Cordeiro (Manchester) </td> </tr> 
            
        <tr> <td>13:30 - 13.50</td> <td> Robustness certification for deep learning, by Yi Dong and Xiaowei Huang(Liverpool) </td> </tr> 

        <tr> <td>13:50 - 14:10</td> <td> Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning, by Chibueze Peace Obioma and Mustafa A. Mustafa (Manchester)  </td> </tr> 

        <tr> <td>14:10 - 14:25</td> <td>Coffee break </td> </tr> 
            
        <tr> <td>14:25 - 14:45</td> <td> Formal Verification of Python and NumPy Programs Using ESBMC, by Bruno Farias and Lucas Cordeiro </td> </tr> 
        <tr> <td>14:45 - 15:05</td> <td> Enhancing Cyber Hygiene for Large Language Models, by Aksshar Ramesh (Sister Project CHAI) </td> </tr> 
        <tr> <td>15:05 - 15:25</td> <td> NLP Verification: Towards Verified Safeguards for LLMs, by Luca Arnaboldi and Ekaterina Komendantskaya (Sister Project AISEC) </td> </tr> 
        <tr> <td>15:25 - 15:45</td> <td> Certified Guidance for Planning with Deep Generative Models, by Mehran Hosseini and Nicola Paoletti </td> </tr> 

        <tr> <td>15:45 - 16:00</td> <td>Coffee break </td> </tr> 
        <tr> <td>16:00 - 16:20</td> <td> Thoughts from the NCSC on the security of AI systems, Martin R3Â (NCSC) </td> </tr> 
        <tr> <td>16:20 - 16:40</td> <td> Socio-technical aspects of AI-powered deepfake fraud, by Meropi Tzanetakis (Manchester) </td> </tr> 
        <tr> <td>16:40 - 17:00</td> <td> Explainable Deepfake Detection: Leveraging Vision-Language Models for Multimedia Authentication, by Guangliang Cheng (Liverpool) </td> </tr> 
        
        <tr> <td>18:00 - 20:00</td> <td>Dinner </td> </tr> </tbody> </table> </section>
        </div>

        <div class="row mt-4 mb-2"> <section class="col-lg-12">
        <h1>Register</h1> <p>This event is by invitation only and is
        intended to establish new partnerships/collaborations to lead
        the discussion concerning the challenges and opportunities and
        tackle our main obstacles to achieving safe and trustable GPAI systems.</p> <p>If you would like to
        attend, please contact our organisation committee: 
        <ul> 
        <li> <a
        href="mailto:Yi.Dong@liverpool.ac.uk">Yi Dong (University of Liverpool)</a></li>
        <li> <a
        href="mailto:Mustafa.Mustafa@manchester.ac.uk">Mustafa Mustafa (University of Manchester)</a></li>
       <li> <a href="mailto:xiaowei.huang@liverpool.ac.uk">Xiaowei
        Huang (University of Liverpool)</a></li> 
        <li> <a
        href="mailto:lucas.cordeiro@manchester.ac.uk">Lucas Cordeiro (University of Manchester)</a></li>
        </ul> </p> </section> </div> </div>

    <div class="container-fluid"> <div class="row"> <footer id="footer"
    class="col-lg-12 mt-5 mb-1 text-center" role="contentinfo"> <a
    href="https://enncore.github.io/" target="_blank">EnnCore</a> <div class="social"> <a target="_blank"
    href="https://twitter.com/?????"> <svg role="img" title="twitter"
    width="30" height="30" viewBox="0 0 1792 1792"> <path d="M1408
    610q-56 25-121 34 68-40 93-117-65 38-134 51-61-66-153-66-87 0-148.5
    61.5T883 722q0 29 5 48-129-7-242-65T454 550q-29 50-29 106 0 114 91
    175-47-1-100-26v2q0 75 50 133.5t123 72.5q-29 8-51 8-13 0-39-4 21 63
    74.5 104t121.5 42q-116 90-261 90-26 0-50-3 148 94 322 94 112 0
    210-35.5t168-95 120.5-137 75-162T1304 746q0-18-1-27 63-45
    105-109zm256-194v960q0 119-84.5 203.5T1376 1664H416q-119
    0-203.5-84.5T128 1376V416q0-119 84.5-203.5T416 128h960q119 0 203.5
    84.5T1664 416z"></path> </svg> </a> <a target="_blank"
    href="https://www.linkedin.com/groups/?????"> <svg role="img"
    title="linkedin" width="30" height="30" viewBox="0 0 1792 1792">
    <path d="M365 1414h231V720H365v694zm246-908q-1-52-36-86t-93-34-94.5
    34-36.5 86q0 51 35.5 85.5T479 626h1q59 0 95-34.5t36-85.5zm585
    908h231v-398q0-154-73-233t-193-79q-136 0-209 117h2V720H723q3 66 0
    694h231v-388q0-38 7-56 15-35 45-59.5t74-24.5q116 0 116
    157v371zm468-998v960q0 119-84.5 203.5T1376 1664H416q-119
    0-203.5-84.5T128 1376V416q0-119 84.5-203.5T416 128h960q119 0 203.5
    84.5T1664 416z"></path> </svg> </a> <a target="_blank"
    href="https://www.youtube.com/channel/?????"> <svg role="img"
    title="youtube" width="30" height="30" viewBox="0 0 1792 1792">
    <path d="M1047 1303v-157q0-50-29-50-17 0-33 16v224q16 16 33 16 29 0
    29-49zm184-122h66v-34q0-51-33-51t-33 51v34zM660
    915v70h-80v423h-74V985h-78v-70h232zm201 126v367h-67v-40q-39 45-76
    45-33 0-42-28-6-16-6-54v-290h66v270q0 24 1 26 1 15 15 15 20 0
    42-31v-280h67zm252 111v146q0 52-7 73-12 42-53 42-35
    0-68-41v36h-67V915h67v161q32-40 68-40 41 0 53 42 7 21 7 74zm251
    129v9q0 29-2 43-3 22-15 40-27 40-80 40-52
    0-81-38-21-27-21-86v-129q0-59 20-86 29-38 80-38t78 38q21 28 21
    86v76h-133v65q0 51 34 51 24 0 30-26 0-1 .5-7t.5-16.5V1281h68zM913
    457v156q0 51-32 51t-32-51V457q0-52 32-52t32 52zm533
    713q0-177-19-260-10-44-43-73.5t-76-34.5q-136-15-412-15-275 0-411
    15-44 5-76.5 34.5T366 910q-20 87-20 260 0 176 20 260 10 43 42.5
    73t75.5 35q137 15 412 15t412-15q43-5 75.5-35t42.5-73q20-84
    20-260zM691 519l90-296h-75l-51 195-53-195h-78l24 69 23 69q35 103 46
    158v201h74V519zm289 81V470q0-58-21-87-29-38-78-38-51 0-78 38-21
    29-21 87v130q0 58 21 87 27 38 78 38 49 0 78-38 21-27 21-87zm181
    120h67V350h-67v283q-22 31-42 31-15 0-16-16-1-2-1-26V350h-67v293q0 37
    6 55 11 27 43 27 36 0 77-45v40zm503-304v960q0 119-84.5 203.5T1376
    1664H416q-119 0-203.5-84.5T128 1376V416q0-119 84.5-203.5T416
    128h960q119 0 203.5 84.5T1664 416z"></path> </svg> </a> </div>
    </footer> </div> </div>


    <script> const popoverTriggerList =
    document.querySelectorAll('[data-bs-toggle="popover"]') const
    popoverList = [...popoverTriggerList].map(popoverTriggerEl => new
    bootstrap.Popover(popoverTriggerEl)) </script> </body>

</html>
